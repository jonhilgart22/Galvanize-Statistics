{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3.3: Continuous Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Continuous Random Variables\n",
    "    * Cumulative distribution function (CDF)\n",
    "    * Probability density function (PDF)\n",
    "    * Mean and variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Continuous probability distributions\n",
    "    * Exponential\n",
    "    * Gamma\n",
    "    * Beta\n",
    "    * Uniform\n",
    "    * Normal\n",
    "    * $\\chi^2$\n",
    "    * Student's t-distribution\n",
    "    * F-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continous Random Variables\n",
    "\n",
    "Yesterday we talked about discrete random variables, for which we can list all the values and their probabilities, even if the list is infinite.   \n",
    "\n",
    "e.g. for $X \\sim Geometric(p)$, \n",
    "\n",
    "| x        |  0  |   1  |    2   | ... |\n",
    "|---------:|:---:|:----:|:------:|:---:|\n",
    "| P(X = x) | $p$ | $pq$ | $pq^2$ | ... |\n",
    "\n",
    "But suppose $X$ takes values in a continuous set, e.g. [0, 1], how can we list all the values $X$ can take?\n",
    "* the smallest number is 0, but what is the next smallest? 0.01? 0.00001? 0.000000001?\n",
    "\n",
    "We can't even begin to list all the values that $X$ can take!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### $P(X = x) = 0$\n",
    "\n",
    "* There are so many numbers in any continuous set that each of them must have probability of 0.\n",
    "\n",
    "* A continuous random takes values in a continous set (a, b).\n",
    "\n",
    "* It describes a continuously varying quantity such as time or height.\n",
    "\n",
    "* When $X$ is continuous, $P(X = x) = 0$ for **ALL** $x$. The probability mass function (PMF) is meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Cumulative Distribution Function (CDF) for Continuous Random Variables\n",
    "\n",
    "Although we cannot assign a probability to any values of $X$, we are able to assign probabilities to intervals.  \n",
    "* e.g. $P(X = 1) = 0$, but $P(0.999 \\leq X \\leq 1.001)$ can be $> 0$.\n",
    "\n",
    "This means we should use the CDF, $F_X(x) = P(X \\leq x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For **discrete** random variables:\n",
    "\n",
    "* $F_X(x) = P(X \\leq x)$\n",
    "* $F_X(x)$ is a step function: probability accumulates in discrete steps\n",
    "* $P(a < X \\leq b) = P(X \\in (a, b]) = F(b) - F(a)$\n",
    "\n",
    "<img src=\"images/cdf_discrete.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For **continuous random variables**:\n",
    "\n",
    "* $F_X(x) = P(X \\leq x)$\n",
    "* $F_X(x)$ is a *continuous* function: probability accumulates *continously*\n",
    "* $P(a < X \\leq b) = P(X \\in (a, b]) = F(b) - F(a)$\n",
    "\n",
    "<img src=\"images/cdf_continuous.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Since $P(X = a) = 0$ for a **continous** random variable:\n",
    "$$ P(a < X < b) = P(a \\leq X \\leq b) = F_X(b) - F_X(a) $$\n",
    "\n",
    "This is **NOT** true for a **discrete** random variable:  \n",
    "$$ P(a < X < b) = P(a + 1 \\leq X \\leq b - 1) = F_X(b - 1) - F_X(a) $$\n",
    "\n",
    "* Endpoints are not important for continuous random variables\n",
    "* Endpoints are **very** important for discrete random variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Probability Density Function (PDF)\n",
    "\n",
    "Although the CDF gives us interval-based tool for dealing with continuous random variables, it is not very good at telling us what the distribution looks like.  \n",
    "For this we use a different tool called the probability density function.  \n",
    "\n",
    "The **probability density function** of a continuous random variable $X$ is defined as,  \n",
    "\n",
    "$$ f_X(x) = \\frac{dF_X}{dx} = F_X^{'}(x)$$\n",
    "\n",
    "So \n",
    "\n",
    "$$ f_X(x) = \\lim_{t \\to 0} \\frac{F_X(x + t) - F_X(x)}{t} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **PDF** gives up:\n",
    "\n",
    "* the RATE at which probability is accumulating at any given point, $F_X^{'}(x)$\n",
    "* the SHAPE of the distribution of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the PDF to Calculate Probabilities\n",
    "\n",
    "The PDF calculates probabilities by integration.\n",
    "\n",
    "Suppose we want to calculate $P(a \\leq X \\leq b)$.\n",
    "\n",
    "We already know that: $P(a \\leq X \\leq b) = F_X(b) - F_X(a)$.\n",
    "\n",
    "But we also know that:\n",
    "\n",
    "$$ f_X(x) = \\frac{dF_X}{dx} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "So\n",
    "\n",
    "$$ F_X(x) = \\int f_X(x) dx $$\n",
    "\n",
    "In fact:\n",
    "\n",
    "$$ F_X(b) - F_X(a) = \\int_{a}^{b} f_X(x) dx $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $X$ be a continuous random variable with probability density function (PDF) $f_X(x)$. Then\n",
    "\n",
    "$$ P(a \\leq X \\leq b) = P(X \\in [a, b]) = \\int_a^b f_X(x) dx $$  \n",
    "\n",
    "This means we can calculate probabilities by integrating the PDF.\n",
    "\n",
    "<img src=\"images/int_pdf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The **total area** under the PDF curve is:\n",
    "\n",
    "$$ \\text{total area } = \\int_{-\\infty}^{\\infty} f_X(x) dx = F_X(\\infty) - F_X(-\\infty) = 1 - 0 = 1$$\n",
    "\n",
    "<img src=\"images/total_pdf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using the PDF to Calculate the CDF\n",
    "\n",
    "$$ F_X(x) = \\int_{-\\infty}^x f_X(u) du $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What You Need to Know\n",
    "\n",
    "* Total area under the PDF curve is: $\\int_{-\\infty}^{\\infty} f_X(x) dx = 1$\n",
    "* The PDF is **NOT** a probability\n",
    "* Calculating probabilities\n",
    "    * $P(a \\leq X \\leq b) = \\int_a^b f_X(x) dx$  \n",
    "    \n",
    "    * $F_X(x) = \\int_{-\\infty}^x f_X(u) du$\n",
    "* Endpoints do NOT matter for continuous random variables: $P(X \\leq a) = P(X < a)$ and $P(X \\geq a) = P(X > a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Expectation / Mean\n",
    "\n",
    "Remember the expectation of a discrete random variable is the long-term average:\n",
    "\n",
    "$$ \\mu_X = E(X) = \\sum_x x P(X = x) = \\sum_x x f_X(x) $$\n",
    "\n",
    "For a continous random variable, we replace the PMF with the PDF, and replace $\\sum_x$ with $\\int_{-\\infty}^{\\infty}$:\n",
    "\n",
    "$$ \\mu_X = E(X) = \\int_{-\\infty}^{\\infty} x f_X(x) dx $$\n",
    "\n",
    "where $f_X(x) = F_X^{'}(x)$ is the PDF. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<img src=\"images/balance.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance\n",
    "\n",
    "If X is continuous, its variance is defined in exactly the same way as a discrete random variable:\n",
    "\n",
    "$$ Var(X) = \\sigma_X^2 = E \\left((X - \\mu_X)^2 \\right) = E(X^2) - \\mu_X^2 = E(X^2) - (E(X))^2 $$\n",
    "\n",
    "For continuous random variable, we can either compute the variance using:\n",
    "\n",
    "$$ Var(X) = E \\left((X - \\mu_X)^2 \\right) = \\int_{-\\infty}^{\\infty} (x - \\mu_X)^2 f_X(x) dx $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ Var(X) = E(X^2) - (E(X))^2 = \\int_{-\\infty}^{\\infty} x^2 f_X(x) dx - (E(X))^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous Probability Distributions\n",
    "\n",
    "### Example: Auckland Volcanoes\n",
    "\n",
    "About 50 volcanic eruptions have occurred in Auckland over the last 100,000 years or so. The first two eruptions occurred in the Auckland Domain and Albert Park. The most recent, and biggest, eruption was Rangitoto, about 600 years ago. There have been about 20 eruptions in the last 20,000 years, which has led the Auckland Regional Council to assess current volcanic risk by assuming that volcanic eruptions in Auckland follow a Poisson process with rate $\\lambda = \\frac{1}{1000}$ volcanoes per year.\n",
    "\n",
    "Q: When will the next volcano erupt in Auckland?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Distribution of Waiting Time in the Poisson Process\n",
    "\n",
    "The length of time between events in the Poisson process is called the waiting time.  \n",
    "\n",
    "Suppose that $\\{N_t : t > 0\\}$ forms a Poisson process with rate $\\lambda = \\frac{1}{1000}$.\n",
    "\n",
    "$N_t$ is the number of volcanoes to have occurred by time t, starting from now.\n",
    "\n",
    "We know that $N_t \\sim Poisson(\\lambda t)$; so $P(N_t = n) = \\frac{(\\lambda t)^n}{n!}e^{-\\lambda t}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $X$ be a continuous random variable giving the number of years waited before the next volcano, starting now.\n",
    "\n",
    "Let's derive an expression for $F_X(x)$.\n",
    "\n",
    "(i) When $x < 0$:  \n",
    "$$ F_X(x) = P(X \\leq x) = P(\\text{less than 0 time before next volcano}) = 0 $$\n",
    "\n",
    "(ii) When $X \\geq 0$:\n",
    "$$ \\begin{align*}\n",
    "     F_X(x) = P(X \\leq x) & = P(\\text{amount of time waited for next volcano} \\leq x) \\\\\n",
    "                          & = P(\\text{there is at least one volcano between now and time x}) \\\\\n",
    "                          & = P(\\text{number of volcanoes between now and time } x \\text{ is } \\geq 1) \\\\\n",
    "                          & = P(N_x \\geq 1) \\\\\n",
    "                          & = 1 - P(N_x = 0) \\\\\n",
    "                          & = 1 - \\frac{(\\lambda x)^0}{0!} e^{-\\lambda x} \\\\\n",
    "                          & = 1 - e^{-\\lambda x}\n",
    "   \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exponential Distribution\n",
    "\n",
    "The distribution of the waiting time $X$ is called the Exponential distribution because of the exponential formula for $F_X(x)$.\n",
    "\n",
    "We define the Exponential($\\lambda$) distribution to be the distribution of the waiting time (time between events) in a Poisson process with rate $\\lambda$.\n",
    "\n",
    "We write $X \\sim Exponential(\\lambda)$, or $X \\sim Exp(\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**CDF**: \n",
    "$$ F_X(x) = P(X \\leq x) =\n",
    "\\begin{cases}\n",
    "    1 - e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
    "    0 & \\text{for } x < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "**PDF**:\n",
    "$$ f_X(x) = F_X^{'}(x) =\n",
    "\\begin{cases}\n",
    "    \\lambda e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
    "    0 & \\text{for } x < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "**Mean**: $\\mu_X = E(X) = \\frac{1}{\\lambda}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = Var(X) = \\frac{1}{\\lambda^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Example\n",
    "\n",
    "What is the probability that there will be a volcanic eruption in Auckland within the next 50 years?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have $\\lambda = \\frac{1}{1000}$, and we need $P(X \\leq 50)$.\n",
    "\n",
    "$$ P(X \\leq 50) = F_X(50) =  1 - e^{-50/1000} = 0.049 $$\n",
    "\n",
    "There is about a 5% chance that there will be a volcanic eruption in Auckland over the next 50 years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The Only Memoryless Distribution\n",
    "\n",
    "The waiting time of the Poisson process can be defined either as the time from the start to the first event, or the time from now until the next event, or the time between any two events.\n",
    "\n",
    "All of these quantities have the same distribution: $X \\sim Exponential(\\lambda)$.\n",
    "\n",
    "This is called the memorylessness property.\n",
    "\n",
    "The distribution of the time from now until the first event is the same as the distribution of the time from the start until the first event: the time from the start till now has been forgotten!\n",
    "\n",
    "<img src=\"images/memoryless.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For volcanoes, memorylessness means that the 600 years we have waited since Rangitoto erupted have counted for nothing.\n",
    "\n",
    "The Exponential distribution is often used to model failure times of components: for example $X \\sim Exponential(\\lambda)$ is the amount of time before a light bulb fails. In this case, memorylessness means that 'old is as good as new', or, put another way, 'new is as bad as old' !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gamma Distribution\n",
    "\n",
    "If $X_1, \\dots, X_k \\sim Exponential(\\lambda)$ and $X_1, \\dots, X_k$ are independent,  \n",
    "then $X_1 + \\dots + X_k \\sim Gamma(k, \\lambda)$.\n",
    "\n",
    "The **Gamma distribution** is defined as the sum of $k$ independent Exponential random variables. It is a very flexbile family of distributions.\n",
    "\n",
    "**Special case**: When $k = 1$, $Gamma(1, \\lambda) = Exponential(\\lambda)$.\n",
    "\n",
    "<img width=\"400\" src=\"images/gamma_pdf.png\">\n",
    "\n",
    "**Note**: in the plot above, $\\theta = 1/\\lambda$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For $X \\sim Gamma(k, \\lambda)$\n",
    "\n",
    "**Probability density distribution (PDF)**:\n",
    "\n",
    "$$ f_X(x) = \n",
    "\\begin{cases}\n",
    "\\frac{\\lambda^k}{\\Gamma(x)} x^{k - 1} e^{-\\lambda x} & \\text{if } x \\geq 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "Where $\\Gamma(x) = \\int_0^{\\infty} t^{x - 1} e^{-t} dt $ (when $x$ is a positive integer, $\\Gamma(x) = (x - 1)!$) \n",
    "\n",
    "\n",
    "**Mean and Variance**: \n",
    "$$E(X) = \\frac{k}{\\lambda} \\text{ and } Var(X) = \\frac{k}{\\lambda^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### CDF\n",
    "<img src=\"images/gamma_cdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Beta Distribution\n",
    "\n",
    "In a Poisson process, if $\\alpha + \\beta$ events occur in a time interval, then the fraction of that interval until the $\\alpha^{th}$ event occurs has a $Beta(\\alpha, \\beta)$ distribution.\n",
    "\n",
    "**Special case**: $Beta(1, 1) = Uniform(0, 1)$\n",
    "\n",
    "<img width = \"400\" src=\"images/beta_pdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For $X \\sim Beta(\\alpha, \\beta)$  \n",
    "\n",
    "\n",
    "**PDF**:\n",
    "$$ f(x) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1} (1 - x)^{\\beta - 1} & \\text{for } 0 < x < 1 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "where $B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1} (1 - t)^{\\beta - 1} dt = \\frac{\\Gamma(\\alpha) \\Gamma(\\beta)}{\\Gamma(\\alpha + \\beta)}$\n",
    "\n",
    "**Mean and Variance**:\n",
    "\n",
    "$$ E(X) = \\frac{\\alpha}{\\alpha + \\beta} \\text{ and } Var(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uniform Distribution\n",
    "\n",
    "$X$ has a Uniform distribution on the interval $[a, b]$ if $X$ is equally likely to fall anywhere in the interval $[a, b]$.  \n",
    "\n",
    "We write $X \\sim Uniform(a, b)$, or $X \\sim U(a, b)$. \n",
    "\n",
    "<img width = \"400\" src=\"images/uniform_pdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**PDF**:\n",
    "\n",
    "$$f_X(x) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{b - a} & \\text{if } a \\leq x \\leq b \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "**Mean and Variance**:\n",
    "\n",
    "$$ E(X) = \\frac{a + b}{2} \\text{ and } Var(X) = \\frac{(b - a)^2}{12} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Exercise**: write out the CDF for $X \\sim Uniform(a, b)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img width = \"400\" src=\"images/uniform_cdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**CDF**:\n",
    "\n",
    "$$ \\begin{align*}\n",
    "     F_X(x) = \\int_{-\\infty}^x f_Y(y) dy & = \\int_a^x \\frac{1}{b - a} dy \\text{   if   } a \\leq x \\leq b \\\\\n",
    "                                         & = \\left[\\frac{y}{b - a}\\right]_a^x \\\\\n",
    "                                         & = \\frac{x - a}{b - a} \\text{   if   } a \\leq x \\leq b\n",
    "   \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normal Distribution\n",
    "\n",
    "The **Normal distribution**, also called the **Gaussian distribution**, is probably the most important distribution in statistics. It has two parameters, the mean $\\mu$ and the variance $\\sigma^2$.  \n",
    "\n",
    "We write $X \\sim Normal(\\mu, \\sigma^2)$, or $X \\sim N(\\mu, \\sigma^2)$.  \n",
    "\n",
    "<img width = \"400\" src=\"images/normal_pdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Density Function (PDF)**:\n",
    "\n",
    "$$ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} exp \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2} \\right) \\text{, for } x \\in R $$\n",
    "\n",
    "**Mean**: $E(X) = \\mu$  \n",
    "\n",
    "**Variance**: $Var(X) = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Linear Transformations\n",
    "\n",
    "If $X \\sim N(\\mu, \\sigma^2)$, the for any constants $a$ and $b$,\n",
    "\n",
    "$$ aX + b \\sim N(a \\mu + b, a^2 \\sigma^2) $$\n",
    "\n",
    "In particular,\n",
    "\n",
    "$$ X \\sim N(\\mu, \\sigma^2) \\Rightarrow \\left(\\frac{X - \\mu}{\\sigma} \\right) \\sim N(0, 1) \\text{ (this is called the standard Normal distribution)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Sum of Normal Random Variables\n",
    "\n",
    "If $X$ and $Y$ are independent, and $X \\sim N(\\mu_1, \\sigma_1^2)$, $Y \\sim N(\\mu_2, \\sigma_2^2)$, then\n",
    "\n",
    "$$ X + Y \\sim N(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ${\\chi}^2$ Distribution\n",
    "\n",
    "The ${\\chi}^2$ distribution is defined as the sum of the squares of $\\nu$ independent standard Normal distribution.  \n",
    "\n",
    "If $X_1, \\dots, X_{\\nu} \\sim N(0, 1)$, and $X_1, \\dots, X_{\\nu}$ are independent,  \n",
    "then $X_1 + \\dots + X_{\\nu} \\sim \\chi^2_{\\nu}$  \n",
    "\n",
    "$\\chi^2_{\\nu}$ is a special case of Gamma distribution,\n",
    "\n",
    "$$ \\chi^2_{\\nu} = Gamma(k = \\frac{\\nu}{2}, \\lambda = \\frac{1}{2}) $$\n",
    "\n",
    "So if $Y \\sim \\chi^2_{\\nu}$, then $E(Y) = \\frac{k}{\\lambda} = \\nu$, and $Var(Y) = \\frac{k}{\\lambda^2} = 2 \\nu$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/chi2_pdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Student's t-distribution\n",
    "\n",
    "If $Y \\sim \\chi^2_{\\nu}$, and $Z \\sim N(0, 1)$ independent of $Y$, then $X = Z / \\sqrt{Y / \\nu}$ has a t-distribution with $\\nu$ degrees of freedom. We write $X \\sim t_{\\nu}$.\n",
    "\n",
    "<img src=\"images/t_pdf.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $F$-distribution\n",
    "\n",
    "If $Y \\sim \\chi^2_{\\nu_1}$ independent of $Z \\sim \\chi^2_{\\nu_2}$, then $X = \\frac{Y / \\nu_1}{Z / \\nu_2}$ has an $F$-distribution with $(\\nu_1, \\nu_2)$ degrees of freedom. We write $X \\sim F(\\nu_1, \\nu_2)$.\n",
    "\n",
    "<img src=\"images/F_pdf.png\">"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
