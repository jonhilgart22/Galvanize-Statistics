{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 3.2: Discrete Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Review: \n",
    "    * Random variable\n",
    "    * Probability mass function (PMF)\n",
    "    * Cumulative distribution function (CDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Common discrete probability distributions\n",
    "    * Bernoulli distribution\n",
    "    * Binomial distribution\n",
    "    * Geometric distribution\n",
    "    * Negative Binomial distribution\n",
    "    * Hypergeometric distribution*\n",
    "    * Multinomial distribution*\n",
    "    * Poission distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Subjective modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random Variables vs Probability Distributions\n",
    "\n",
    "* A **random variable** is a function from a sample space $\\Omega$ to the real numbers $R$, $X: \\Omega \\rightarrow R$. In other words, a random variable is a way of assigning numerical values to the outcomes of a random experiment.  \n",
    "    * e.g. Toss a coin twice, the sample space is   \n",
    "    $\\Omega = \\{HH, HT, TH, TT\\}$  \n",
    "    Let random variable $X$ be the number of heads in the outcome, then  \n",
    "    $X(HH) = 2, X(HT) = 1, X(TH) = 1, X(TT) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* A **probability distribution** is a function that describes the probability of a random variable taking certain values. In other words, it is the \"rule\" that associates probabilities with specific values or ranges of values of a random variable. \n",
    "    * The probability distribution of a discrete random variable is a list of probabilities associated with each of its possible values.  \n",
    "\n",
    "|x        |  0  |  1  |  2  |  \n",
    "|:--------|:---:|:---:|:---:|  \n",
    "|P(X = x) | 1/4 | 1/2 | 1/4 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* **Probability mass function (PMF)**: It tells us the probability that a **discrete** random variable $X$ is equal to a certain value. We define it as \n",
    "\n",
    "$$ f_X (x) = P (X = x) $$\n",
    "\n",
    "* **Cumulative distribution function (CDF)**: It gives us the probability that a random variable $X$ is less than or equal to a certain value. We define it as\n",
    "\n",
    "$$ F_X (x) = P( X \\leq x) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete Probability Distributions\n",
    "\n",
    "### Bernoulli Distribution (Bernoulli Trials)\n",
    "\n",
    "Many of the discrete random variables that we are going to meet today are based on counting the outcomes of a series of trials called Bernoulli trials. Jacques Bernoulli was a Swiss mathematician in the late 1600s. He and his brother Jean, who were bitter rivals, both studied mathematics secretly against their father's will. Their father wanted Jacques to be a theologist and Jean to be a merchant.\n",
    "\n",
    "The **Bernoulli distribution** is the probability distribution of a random variable which takes the value 1 with success probability of $p$ and the value 0 with failure probability of $q = 1 - p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Examples**:\n",
    "1. Tossing a fair coin, $P(success) = P(head) = 1/2$\n",
    "2. Tossing a fair die, success = \"6\", failure = \"not 6\", $P(success) = 1/6$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The random variable $X$ is called a **Bernoulli random variable** if it takes only 2 values, 0 and 1.\n",
    "\n",
    "\n",
    "The probability mass function is,\n",
    "\n",
    "$$f_X(x)=\n",
    "\\begin{cases}\n",
    "    p, & \\text{if } x = 1\\\\\n",
    "    1 - p, & \\text{if } x = 0\n",
    "\\end{cases}$$\n",
    "\n",
    "That is,\n",
    "\n",
    "$$\\begin{align*}\n",
    "P(Y = 1) & = P(success) = p \\\\\n",
    "P(Y = 0) & = P(failure) = 1- p\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binomial Distribution\n",
    "\n",
    "Let $X$ be the number of successes in $n$ independent Bernoulli trials each with probability of success $= p$, then $X$ has the **Binomial distribution** with parameters $n$ and $p$. We write $X \\sim Bin(n, p)$, or $X \\sim Binomial(n, p)$.\n",
    "\n",
    "**Examples**: Let $X = $ number of heads in 10 coin tosses, assuming the coin is fair, $X \\sim Bin(n = 10, p = 0.5)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probability Mass Function (PMF)**:\n",
    "$$f_X(x) = P(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x} \\text{ for } x = 0, 1, \\dots, n$$\n",
    "\n",
    "**Mean**: $\\mu = np$\n",
    "\n",
    "**Variance**: $\\sigma^2 = np(1 - p) = npq$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/bin_pmf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example 1**: Let $X \\sim Binomial(n = 4, p = 0.2)$. Write down the probability function of $X$.\n",
    "\n",
    "|                 x  |    0   |    1   |    2   |    3   |    4   |\n",
    "|-------------------:|:------:|:------:|:------:|:------:|:------:|\n",
    "|$f_x(x)$ = P(X = x) | 0.4096 | 0.4096 | 0.1536 | 0.0256 | 0.0016 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sum of Independent Binomial Distributions\n",
    "\n",
    "If $X$ and $Y$ are independent, and $X \\sim Binomial(n, p)$, $Y \\sim Binomial(m, p)$, then  \n",
    "$X + Y \\sim Bin(n + m, p)$\n",
    "\n",
    "\n",
    "**Note**: $X$ and $Y$ must share the same value of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cumulative Distribution Function (CDF):\n",
    "\n",
    "$$ F_X(x) = P(X \\leq x) = \\sum_{y \\leq x} f_X(y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example**: Let $X \\sim Binomial(2, \\frac{1}{2})$.\n",
    "\n",
    "|x        |  0  |  1  |  2  |  \n",
    "|:--------|:---:|:---:|:---:|  \n",
    "|P(X = x) | 1/4 | 1/2 | 1/4 |\n",
    "\n",
    "Then  \n",
    "$$F_X(x) = P(X \\leq x) = \n",
    "\\begin{cases}\n",
    "    0 & \\text{if } x < 0 \\\\\n",
    "    0.25 & \\text{if } 0 \\leq x < 1 \\\\\n",
    "    0.25 + 0.5 = 0.75 & \\text{if } 1 \\leq x < 2 \\\\\n",
    "    0.25 + 0.5 + 0.25 = 1 & \\text{if } x \\geq 2\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/bin_cdf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Note that $F_X(x)$ is a **step function**: it jumps by amount $f_X(y)$ at every point $y$ with positive probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example 2**: Let $X$ be the number of times I get a '6' out of 10 rolls of a fair die.\n",
    "\n",
    "1. What is the distribution of $X$?\n",
    "2. What is the probability that $X \\geq 2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. $X \\sim Binomial(n = 10, p = 1/6)$\n",
    "\n",
    "2. \n",
    "\n",
    "$$ \\begin{align*}\n",
    "        P(X \\geq 2) & = 1 - P(X < 2) \\\\\n",
    "                    & = 1 - P(X = 0) - P(X = 1) \\\\\n",
    "                    & = 1 - \\binom{10}{0} \\left(\\frac{1}{6}\\right)^0 \\left(1 - \\frac{1}{6}\\right)^{10 - 0} \n",
    "                          - \\binom{10}{1} \\left(\\frac{1}{6}\\right)^1 \\left(1 - \\frac{1}{6}\\right)^{10 - 1} \\\\\n",
    "                    & = 0.515\n",
    "      \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Geometric Distribution\n",
    "\n",
    "Like the Binomial distribution, the Geometric distribution is defined in terms of a sequence of Bernoulli trials.  \n",
    "\n",
    "* The Binomial distribution counts the number of successes out of a fixed number of trials.\n",
    "\n",
    "* The Geometric distribution counts the number of trials until the first success occurs.\n",
    "\n",
    "\n",
    "**Geometric distribution**: When independent Bernoulli trials are repeated, each with probability $p$ of success, the number of trails $X$ it takes to get the first success has a Geometric distribution. We write $X \\sim Geometric(p)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probability Mass Function (PMF)**:\n",
    "\n",
    "$$ f_X(x) = (1 - p)^{x - 1} p = q^{x - 1} p \\text{, for } x = 1, 2, \\dots $$\n",
    "\n",
    "**Mean**: $\\mu = \\frac{1}{p}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\frac{1 - p}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/geo_pmf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Negative Binomial Distribution\n",
    "\n",
    "When independent Bernoulli trials are repeated, each with probability $p$ of success, and $X$ is the trial number when $r$ successes are first achieved, then $X$ has a Negative Binomial distribution. We write $X \\sim NegBin(r, p)$.\n",
    "\n",
    "If $X_1, \\dots, X_k$ are independent, and each $X_i \\sim Geometric(p)$, then  \n",
    "\n",
    "$$ X_1 + \\dots + X_k \\sim NegBin(k, p) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = \\binom{x - 1}{r - 1} p^r (1 - p)^{x - r} \\text{, for } x = r, r + 1, \\dots $$\n",
    "\n",
    "**mean**: $\\mu = \\frac{r}{p}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\frac{r(1 - p)}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/nbin_pmf.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypergeometric Distribution\n",
    "\n",
    "The Hypergeometric distribution is used when we are sampling _without_ replacement from a *finite* population.  \n",
    "\n",
    "In a Bernoulli process, given that there are $M$ successes among $N$ trials, the number $X$ of successes among the first $n$ trials has a Hypergeometric distribution. We write $X \\sim Hypergeometric(N, M, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = \\frac{\\binom{M}{x} \\binom{N - M}{n - x}}{\\binom{N}{n}} \\text{, for } x = 0, 1, \\dots, n $$\n",
    "\n",
    "**Mean**: $\\mu = np$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\binom{N - n}{N - 1} np(1-p)$ where $p = \\frac{M}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/hgeo_pmf.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multinomial Distribution\n",
    "\n",
    "The Multinomial distribution is a generalization of the Binomial distribution. For each independent trial, instead of having only two possible outcomes, success and failure, we can have k possible outcomes, with probabilities $p_1, \\dots, p_k$, where $p_i \\geq 0$ for $i = 1, \\dots, k$ and $\\sum_{i = 1}^{k} p_i = 1$. For $n$ independent trials, if random variable $X_i$ indicates the number of times outcome number $i$ is observed over the $n$ trials, the vector $X = (X_1, \\dots, X_k)$ follows a Multinomial distribution with parameters $n$ and $p = (p_1, \\dots, p_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f(x_1, \\dots, x_k) = P(X_1 = x_1, \\dots, X_k = x_k) = \\frac{n!}{x_1! \\dots x_k!} p_1^{x_1} \\dots p_k^{x_k} \\text{ for } \\sum_{i = 1}^k x_i = n $$\n",
    "\n",
    "**Mean**: $E(X_i) = n p_i$\n",
    "\n",
    "**Variance**: $Var(X_i) = n p_i (1 - p_i)$  \n",
    "\n",
    "**Covariance**: $Cov(X_i, X_j) = -n p_i p_j$ for $i \\neq j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "The **Poisson distribution** is a distribution that counts the number of random events in a fixed interval of time or space.\n",
    "\n",
    "How many cars will cross the Golden Gate Bridge today? $X \\sim Poisson$.  \n",
    "How many road accidents will there be in the US this year? $X \\sim Poisson$.   \n",
    "How many volcanoes will erupt over the next 1000 years? $X \\sim Poisson$.    \n",
    "\n",
    "The **Poisson process** counts the number of events occurring in a fixed time or space, when events occur independently and at a constant average rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example**: Let $X$ be the number of road accidents in a year in the US. Suppose that:\n",
    "\n",
    "1. all accidents are independent of each other\n",
    "2. accidents occur at a constant rate of $\\lambda$ per year\n",
    "3. accidents cannot occur simultaneously  \n",
    "\n",
    "Then the number of accidents in a year, $X$, has the distribution\n",
    "$$ X \\sim Poisson(\\lambda) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = P(X = x) = \\frac{\\lambda^x}{x!} e^{-\\lambda} \\text{ for } x = 0, 1, 2, \\dots $$\n",
    "\n",
    "**Mean**: $\\mu = \\lambda$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/pois_pmf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Number of accidents in $t$ years**\n",
    "\n",
    "Let $X_t$ be the number of accidents to occur in $t$ years, then\n",
    "$$ X_t \\sim Poisson(\\lambda t) $$\n",
    "\n",
    "and\n",
    "\n",
    "$$ P(X_t = x) = \\frac{(\\lambda t)^x}{x!} e^{-\\lambda t} \\text{ for } x = 0, 1, 2, \\dots $$\n",
    "\n",
    "**Q**: What are the mean and variance of $X_t$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sum of independent Poisson random variables\n",
    "\n",
    "If $X$ and $Y$ are independent, and $X \\sim Poisson(\\lambda)$, $Y \\sim Poisson(\\mu)$, then  \n",
    "\n",
    "$$ X + Y \\sim Poisson(\\lambda + \\mu) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Subjective Modeling\n",
    "\n",
    "Most of the distributions we have talked about are exact models for the situation described. For example, the Binomial distribution describes exactly the distribution of the number of successes in n Bernoulli trials. However, there is often no exact model available, in which case we would use a **subjective model**.\n",
    "\n",
    "In a subjective model, we pick a probability distribution to describe a situation just because it has properties that we think are appropriate to the situation, such as the right sort of symmetry or skew, or the right sort of relationship between variance and mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example 1**: Distribution of word lengths in English.  \n",
    "Let $X =$ number of letters in an English word chosen at random from the dictionary.  \n",
    "\n",
    "If we plot the frequencies on a histogram, we see that the shape of the distribution is roughly Poisson.\n",
    "\n",
    "$$ X - 1 \\sim Poisson(6.22) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/word_length.png\" width=\"400\">\n",
    "\n",
    "**Note**: We need to use $X \\sim 1 + Poisson$ because $X$ cannot take the value 0.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The fit of the Poisson distribution is fairly good.  \n",
    "\n",
    "In this example we can not say that the Poisson distribution represents the number of events in a fixed time or space: instead, it is being used as a subjective model for word length.\n",
    "\n",
    "Can a Poisson distribution fit any data? No. The Poisson distribution is rather inflexible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Example 2**: Distribution of stroke counts of Chinese characters.  \n",
    "Let $X =$ the number of strokes in a randomly chosen character.  \n",
    "\n",
    "The best-fitting Poisson distribution looks like this, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"images/poisson_fit.png\" width=\"400\">\n",
    "\n",
    "**Note**: The best fit is found by Maximum Likelihood Estimate (MLE) which we will cover later in the course.\n",
    "\n",
    "In this case, the fit of the Poisson distribution is not so good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out, $X$ can be better described by a Negative Binomial model, $NegBin(k = 23.7, p = 0.64)$ (found by MLE).\n",
    "\n",
    "<img src=\"images/negbin_fit.png\" width=\"400\">\n",
    "\n",
    "The fit of the Negative Binomial distribution is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, $X$ does not represent the number of failures before the k'th success: the Negative Binomial model is a subjective model that has the right shape to describe the distribution of stroke counts of Chinese characters."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
