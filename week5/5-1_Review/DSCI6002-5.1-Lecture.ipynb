{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 5.1: Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Discrete probability distributions\n",
    "    * Bernoulli distribution\n",
    "    * Binomial distribution\n",
    "    * Geometric distribution\n",
    "    * Negative Binomial distribution\n",
    "    * Hypergeometric distribution\n",
    "    * Multinomial distribution\n",
    "    * Poission distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Continuous probability distributions\n",
    "    * Exponential\n",
    "    * Gamma\n",
    "    * Uniform\n",
    "    * Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Relationshop between two random variables\n",
    "    * The joint distribution function\n",
    "    * Marginal distributions\n",
    "    * Independent random variables\n",
    "    * Conditional distributions\n",
    "    * Conditional expectation\n",
    "    * Combining random variables\n",
    "        * Covariance\n",
    "        * Correlation\n",
    "        * Mean\n",
    "        * Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Point estimation\n",
    "    * Maximum likelihood estimation (MLE)\n",
    "    * Method of moments (MOM)\n",
    "    * Mean squared error (MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Central Limit Theorem (CLT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Confidence intervals\n",
    "    * One sample - mean and proportion\n",
    "    * Two samples - difference in means and proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Discrete Probability Distributions\n",
    "\n",
    "### Bernoulli Distribution (Bernoulli Trials)\n",
    "\n",
    "The **Bernoulli distribution** is the probability distribution of a random variable which takes the value 1 with success probability of $p$ and the value 0 with failure probability of $q = 1 - p$.\n",
    "\n",
    "The random variable $X$ is called a **Bernoulli random variable** if it takes only 2 values, 0 and 1.\n",
    "\n",
    "\n",
    "The probability mass function is,\n",
    "\n",
    "$$f_X(x)=\n",
    "\\begin{cases}\n",
    "    p, & \\text{if } x = 1\\\\\n",
    "    1 - p, & \\text{if } x = 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Binomial Distribution\n",
    "\n",
    "Let $X$ be the number of successes in $n$ independent Bernoulli trials each with probability of success $= p$, then $X$ has the **Binomial distribution** with parameters $n$ and $p$. We write $X \\sim Bin(n, p)$, or $X \\sim Binomial(n, p)$.\n",
    "\n",
    "**Probability Mass Function (PMF)**:\n",
    "$$f_X(x) = P(X = x) = \\binom{n}{x} p^x (1 - p)^{n - x} \\text{ for } x = 0, 1, \\dots, n$$\n",
    "\n",
    "**Mean**: $\\mu = np$\n",
    "\n",
    "**Variance**: $\\sigma^2 = np(1 - p) = npq$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Geometric Distribution\n",
    "\n",
    "**Geometric distribution**: When independent Bernoulli trials are repeated, each with probability $p$ of success, the number of trails $X$ it takes to get the first success has a Geometric distribution. We write $X \\sim Geometric(p)$.\n",
    "\n",
    "**Probability Mass Function (PMF)**:\n",
    "\n",
    "$$ f_X(x) = (1 - p)^{x - 1} p = q^{x - 1} p \\text{, for } x = 1, 2, \\dots $$\n",
    "\n",
    "**Mean**: $\\mu = \\frac{1}{p}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\frac{1 - p}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Negative Binomial Distribution\n",
    "\n",
    "When independent Bernoulli trials are repeated, each with probability $p$ of success, and $X$ is the trial number when $r$ successes are first achieved, then $X$ has a Negative Binomial distribution. We write $X \\sim NegBin(r, p)$.\n",
    "\n",
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = \\binom{x - 1}{r - 1} p^r (1 - p)^{x - r} \\text{, for } x = r, r + 1, \\dots $$\n",
    "\n",
    "**mean**: $\\mu = \\frac{r}{p}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\frac{r(1 - p)}{p^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hypergeometric Distribution\n",
    "\n",
    "The Hypergeometric distribution is used when we are sampling without replacement from a *finite* population.  \n",
    "\n",
    "In a Bernoulli process, given that there are $M$ successes among $N$ trails, the number $X$ of successes among the first $n$ trials has a Hypergeometric distribution. We write $X \\sim Hypergeometric(N, M, n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = \\frac{\\binom{M}{x} \\binom{N - M}{n - x}}{\\binom{N}{n}} \\text{, for } x = 0, 1, \\dots, n $$\n",
    "\n",
    "**Mean**: $\\mu = np$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\binom{N - n}{N - 1} np(1-p)$ where $p = \\frac{M}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Multinomial Distribution\n",
    "\n",
    "The Multinomial distribution is a generalization of the Binomial distribution. For each independent trial, instead of having only two possible outcomes, success and failure, we can have k possible outcomes, with probabilities $p_1, \\dots, p_k$, where $p_i \\geq 0$ for $i = 1, \\dots, k$ and $\\sum_{i = 1}^{k} p_i = 1$. For $n$ independent trials, if random variable $X_i$ indicates the number of times outcome number $i$ is observed over the $n$ trials, the vector $X = (X_1, \\dots, X_k)$ follows a Multinomial distribution with parameters $n$ and $p = (p_1, \\dots, p_k)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Mass Function**:\n",
    "\n",
    "$$\\begin{align}f(x_1, \\dots, x_k) &= P(X_1 = x_1, \\dots, X_k = x_k) \\\\&= \\frac{n!}{x_1! \\dots x_k!} p_1^{x_1} \\dots p_k^{x_k} \\\\\\text{ for } \\sum_{i = 1}^k x_i = n \\end{align}$$\n",
    "\n",
    "**Mean**: $E(X_i) = n p_i$\n",
    "\n",
    "**Variance**: $Var(X_i) = n p_i (1 - p_i)$  \n",
    "\n",
    "**Covariance**: $Cov(X_i, X_j) = -n p_i p_j$ for $i \\neq j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Poisson Distribution\n",
    "\n",
    "The **Poisson distribution** is a distribution that counts the number of random events in a fixed space of time.\n",
    "\n",
    "**Probability Mass Function**:\n",
    "\n",
    "$$ f_X(x) = P(X = x) = \\frac{\\lambda^x}{x!} e^{-\\lambda} \\text{ for } x = 0, 1, 2, \\dots $$\n",
    "\n",
    "**Mean**: $\\mu = \\lambda$\n",
    "\n",
    "**Variance**: $\\sigma^2 = \\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 1:\n",
    "\n",
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(a) What is the probability the first blue-eyed child they have is their third child? Assume that the eye colors of the children are independent of each other.  \n",
    "\n",
    "(b) On average, how many children would such a pair of parents have until having a blue-eyed child? What is the standard deviation of the number of children they have until the first blue-eyed child?  \n",
    "\n",
    "(c) What is the probability that their first child will have green eyes and the second will not?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(d) What is the probability that exactly one of their two children will have green eyes?  \n",
    "\n",
    "(e) If they have six children, what is the probability that exactly two will have green eyes?  \n",
    "\n",
    "(f) If they have six children, what is the probability that at least one will have green eyes?  \n",
    "\n",
    "(g) What is the probability that the first green eyed child will be the 4th child?  \n",
    "\n",
    "(h) Would it be considered unusual if only 2 out of their 6 children had brown eyes?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(a) What is the probability the first blue-eyed child they have is their third child? Assume that the eye colors of the children are independent of each other.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).    \n",
    "\n",
    "(b) On average, how many children would such a pair of parents have until having a blue-eyed child? What is the standard deviation of the number of children they have until the first blue-eyed child?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(c) What is the probability that their first child will have green eyes and the second will not?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(d) What is the probability that exactly one of their two children will have green eyes?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(e) If they have six children, what is the probability that exactly two will have green eyes? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(f) If they have six children, what is the probability that at least one will have green eyes?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(g) What is the probability that the first green eyed child will be the 4th child?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A husband and wife both have brown eyes but carry genes that make it possible for their children to have brown eyes (probability 0.75), blue eyes (0.125), or green eyes (0.125).  \n",
    "\n",
    "(h) Would it be considered unusual if only 2 out of their 6 children had brown eyes?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 2:\n",
    "\n",
    "A coffee shop serves an average of 75 customers per hour during the morning rush.  \n",
    "\n",
    "(a) Which distribution would be the most appropriate for calculating the probability of a given number of customers arriving within one hour during this time of day?  \n",
    "\n",
    "(b) What are the mean and the standard deviation of the number of customers this coffee shop\n",
    "serves in one hour during this time of day?  \n",
    "\n",
    "(c) Calculate the probability that this coffee shop serves more than 70 customers in one hour during this\n",
    "time of day?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A coffee shop serves an average of 75 customers per hour during the morning rush.  \n",
    "\n",
    "(a) Which distribution would be the most appropriate for calculating the probability of a given number of customers arriving within one hour during this time of day?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A coffee shop serves an average of 75 customers per hour during the morning rush.  \n",
    "\n",
    "(b) What are the mean and the standard deviation of the number of customers this coffee shop\n",
    "serves in one hour during this time of day?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A coffee shop serves an average of 75 customers per hour during the morning rush.  \n",
    "\n",
    "(c) Calculate the probability that this coffee shop serves more than 70 customers in one hour during this\n",
    "time of day?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Continuous Probability Distributions\n",
    "\n",
    "### $P(X = x) = 0$\n",
    "\n",
    "* When $X$ is continuous, $P(X = x) = 0$ for **ALL** $x$. The probability mass function (PMF) is meaningless.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### The CDF\n",
    "\n",
    "* $F_X(x) = P(X \\leq x)$\n",
    "* $F_X(x)$ is a *continuous* function: probability accumulates *continously*\n",
    "* $P(a < X \\leq b) = P(X \\in (a, b]) = F(b) - F(a)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The PDF\n",
    "\n",
    "$$ f_X(x) = \\frac{dF_X}{dx} = F_X^{'}(x)$$\n",
    "\n",
    "<img src=\"images/total_pdf.png\" width=\"500\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$P(a \\leq X \\leq b) = F(b) - F(a) = \\int_a^b f_X(x) dx$ \n",
    "\n",
    "<img src=\"images/int_pdf.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mean and Variance\n",
    "\n",
    "$$ \\mu_X = E(X) = \\int_{-\\infty}^{\\infty} x f_X(x) dx $$\n",
    "\n",
    "$$ Var(X) = E \\left((X - \\mu_X)^2 \\right) = \\int_{-\\infty}^{\\infty} (x - \\mu_X)^2 f_X(x) dx $$\n",
    "\n",
    "or\n",
    "\n",
    "$$ Var(X) = E(X^2) - (E(X))^2 = \\int_{-\\infty}^{\\infty} x^2 f_X(x) dx - (E(X))^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exponential Distribution\n",
    "\n",
    "We define the Exponential($\\lambda$) distribution to be the distribution of the waiting time (time between events) in a Poisson process with rate $\\lambda$.\n",
    "\n",
    "We write $X \\sim Exponential(\\lambda)$, or $X \\sim Exp(\\lambda)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**CDF**: \n",
    "$$ F_X(x) = P(X \\leq x) =\n",
    "\\begin{cases}\n",
    "    1 - e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
    "    0 & \\text{for } x < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "**PDF**:\n",
    "$$ f_X(x) = F_X^{'}(x) =\n",
    "\\begin{cases}\n",
    "    \\lambda e^{-\\lambda x} & \\text{for } x \\geq 0 \\\\\n",
    "    0 & \\text{for } x < 0\n",
    "\\end{cases}$$\n",
    "\n",
    "**Mean**: $\\mu_X = E(X) = \\frac{1}{\\lambda}$\n",
    "\n",
    "**Variance**: $\\sigma^2 = Var(X) = \\frac{1}{\\lambda^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gamma Distribution\n",
    "\n",
    "The **Gamma distribution** is defined as the sum of $k$ independent Exponential random variables. It is a very flexbile family of distributions.\n",
    "\n",
    "For $X \\sim Gamma(k, \\lambda)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability density distribution (PDF)**:\n",
    "\n",
    "$$ f_X(x) = \n",
    "\\begin{cases}\n",
    "\\frac{\\lambda^k}{\\Gamma(x)} x^{k - 1} e^{-\\lambda x} & \\text{if } x \\geq 0 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "Where $\\Gamma(x) = \\int_0^{\\infty} t^{x - 1} e^{-t} dt $ (when $x$ is a positive integer, $\\Gamma(x) = (x - 1)!$) \n",
    "\n",
    "\n",
    "**Mean and Variance**: \n",
    "$$E(X) = \\frac{k}{\\lambda} \\text{ and } Var(X) = \\frac{k}{\\lambda^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Uniform Distribution\n",
    "\n",
    "$X$ has a Uniform distribution on the interval $[a, b]$ if $X$ is equally likely to fall anywhere in the interval $[a, b]$.  \n",
    "\n",
    "We write $X \\sim Uniform(a, b)$, or $X \\sim U(a, b)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**PDF**:\n",
    "\n",
    "$$f_X(x) = \n",
    "\\begin{cases}\n",
    "\\frac{1}{b - a} & \\text{if } a \\leq x \\leq b \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases} $$\n",
    "\n",
    "**Mean and Variance**:\n",
    "\n",
    "$$ E(X) = \\frac{a + b}{2} \\text{ and } Var(X) = \\frac{(b - a)^2}{12} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Normal Distribution\n",
    "\n",
    "The **Normal distribution**, also called the **Gaussian distribution**, is probably the most important distribution in statistics. It has two parameters, the mean $\\mu$ and the variance $\\sigma^2$.  \n",
    "\n",
    "We write $X \\sim Normal(\\mu, \\sigma^2)$, or $X \\sim N(\\mu, \\sigma^2)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Probability Density Function (PDF)**:\n",
    "\n",
    "$$ f(x) = \\frac{1}{\\sigma \\sqrt{2 \\pi}} exp \\left(- \\frac{(x - \\mu)^2}{2 \\sigma^2} \\right) \\text{, for } x \\in R $$\n",
    "\n",
    "**Mean**: $E(X) = \\mu$  \n",
    "\n",
    "**Variance**: $Var(X) = \\sigma^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Linear Transformations\n",
    "\n",
    "If $X \\sim N(\\mu, \\sigma^2)$, the for any constants $a$ and $b$,\n",
    "\n",
    "$$ aX + b \\sim N(a \\mu + b, a^2 \\sigma^2) $$\n",
    "\n",
    "In particular,\n",
    "\n",
    "$$ X \\sim N(\\mu, \\sigma^2) \\Rightarrow \\left(\\frac{X - \\mu}{\\sigma} \\right) \\sim N(0, 1) $$\n",
    "\n",
    "Note: $N(0, 1)$ is called the **standard Normal distribution**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Sum of Normal Random Variables\n",
    "\n",
    "If $X$ and $Y$ are independent, and $X \\sim N(\\mu_1, \\sigma_1^2)$, $Y \\sim N(\\mu_2, \\sigma_2^2)$, then\n",
    "\n",
    "$$ X + Y \\sim N(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 3:\n",
    "\n",
    "The daily high temperature in September in San Francisco is approximately Normally distributed with an average high of 70°F and a standard deviation of 8°F.  \n",
    "\n",
    "(a) What is the probability that a day in September would have a high of 68°F or colder?  \n",
    "\n",
    "(b) What high temperature needs to be achieved in order to be in the top 1% of daily high temps September?\n",
    "\n",
    "(c) Say the temperature right now is 72°F, what is the probability that today's high temperature is higher than 75°F?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The daily high temperature in September in San Francisco is approximately Normally distributed with an average high of 70°F and a standard deviation of 8°F.  \n",
    "\n",
    "(a) What is the probability that a day in September would have a high of 68°F or colder?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The daily high temperature in September in San Francisco is approximately Normally distributed with an average high of 70°F and a standard deviation of 8°F.  \n",
    "\n",
    "(b) What high temperature needs to be achieved in order to be in the top 1% of daily high temps September?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The daily high temperature in September in San Francisco is approximately Normally distributed with an average high of 70°F and a standard deviation of 8°F.  \n",
    "\n",
    "(c) Say the temperature right now is 72°F, what is the probability that today's high temperature is higher than 75°F?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 4:\n",
    "\n",
    "Customers arrive at a coffee shop at an average rate of 75 per hour during the morning rush.\n",
    "\n",
    "(a) The coffee shop opens at 7am, on average, how long do they have to wait until the first customer arrives?\n",
    "\n",
    "(b) What is the probability that the first customer arrives within the first 3 minutes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A coffee shop serves an average of 75 customers per hour during the morning rush.\n",
    "\n",
    "(a) The coffee shop opens at 7am, on average, how long do they have to wait until the first customer arrives?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A coffee shop serves an average of 75 customers per hour during the morning rush.\n",
    "\n",
    "(b) What is the probability that the first customer arrives within the first 3 minutes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 5:\n",
    "\n",
    "Let $X_i$ denote the weight of a randomly selected prepackaged one-pound bag of carrots. Of course, one-pound bags of carrots won't weigh exactly one pound. In fact, history suggests that $X_i$ is Normally distributed with a mean of 1.18 pounds and a standard deviation of 0.07 pound. Now, let $W$ denote the weight of a randomly selected prepackaged three-pound bag of carrots. Three-pound bags of carrots won't weigh exactly three pounds either. In fact, history suggests that W is Normally distributed with a mean of 3.22 pounds and a standard deviation of 0.09 pound. Selecting bags at random, what is the probability that the sum of three one-pound bags exceeds the weight of one three-pound bag?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relationshop Between Two Random Variables\n",
    "\n",
    "### The Joint Distribution Function\n",
    "\n",
    "* When we deal with two discrete random variables, $X$ and $Y$, it is convenient to work with joint probabilities. We define the joint probability distribution to be    \n",
    "\n",
    "\n",
    "$$ f_{X, Y} (x, y) = P(X = x \\text{ and } Y = y) $$\n",
    "\n",
    "* As usual, we require that  \n",
    "\n",
    "\n",
    "$$f_{X, Y} (x, y) \\geq 0 \\text{ for any pairs } x, y$$  \n",
    "    \n",
    "$$\\sum_{\\text{all } x, y} f_{X, Y} (x, y) = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Marginal Distributions\n",
    "\n",
    "* Suppose we are interested only in $X$, yet have to work with the joint distribution of $X$ and $Y$. We can obtain the marginal distribution of $X$ as follows.  \n",
    "\n",
    "* The marginal probabilities of $X$ and $Y$ are given by  \n",
    "    \n",
    "    $$ f_X(x) = \\sum_y f_{X, Y} (x, y) $$\n",
    "    $$ f_Y(y) = \\sum_x f_{X, Y} (x, y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Independence\n",
    "\n",
    "* Two random variables $X$ and $Y$ are called independent if the events ($X = x$) and ($Y = y$) are independent. That is,\n",
    "\n",
    "* The random variables $X$ and $Y$ are independent if for all values of x and y:\n",
    "\n",
    "$$ f_{X, Y} (x, y) = f_X (x) f_Y(y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Distributions\n",
    "\n",
    "* Let $X$ and $Y$ be jointly distributed random variables. Then the conditional distribution of $X$ given $Y$ is given by\n",
    "\n",
    "$$ f_{X|Y} (X = x | Y = y) = \\frac{f_{X, Y} (x, y)}{f_Y (y)} $$\n",
    "\n",
    "* Note that for a given $y$ value, $P(X = x | Y = y)$ is a probability distribution. That is, for any value $y$\n",
    "\n",
    "$$ \\sum_{\\text{all } x \\text{ values}} P(X = x | Y = y) = 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional Expectation\n",
    "\n",
    "* One useful application of conditional distributions is in calculating conditional expectations. You will see a lot more of this when we get to regression analysis.\n",
    "\n",
    "* The basic idea is that given a conditional distribution, we can also calculate a conditional expectation:\n",
    "\n",
    "$$ E(X | Y = y) = \\sum_{\\text{all } x \\text{ values}} x P(X = x | Y = y) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Covariance\n",
    "\n",
    "* The covariance is a measure of the linear association of two random variables. Its sign reflects the direction of the association; if the variables tend to move in the same direction the covariance is positive. If the variables tend to move in opposite directions the covariance is negative.\n",
    "\n",
    "\n",
    "$$ \\begin{align}Cov(X, Y) = \\sigma_{XY} &= E[(X - E(X)(Y - E(Y))] \\\\ &= \\sum_{i = 1}^N (x_i - E(X))(y_i - E(Y))P(x_i, y_i)\\end{align} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* The covariance can also be expressed as\n",
    "\n",
    "$$ Cov(X, Y) = E(XY) - E(X)E(Y) $$\n",
    "\n",
    "* Two interesting facts\n",
    "    * $Cov(X, X) = Var(X)$    \n",
    "    * if $X$ and $Y$ are **independent**, $Cov(X, Y) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Covariance and Independence\n",
    "\n",
    "* IF $X$ and $Y$ are independent, then $Cov(X, Y) = 0$.\n",
    "* But the reverse is not always true!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Correlation: Covariance Rescaled\n",
    "\n",
    "\n",
    "$$ \\rho = \\frac{\\sigma_{X, Y}}{\\sigma_X \\sigma_Y} $$\n",
    "\n",
    "* This is a unitless measure of association.\n",
    "\n",
    "* The correlation is always between -1 and 1, with 1 indicating a perfect positive linear relationship, -1 a perfect negative linear relationship and 0 no linear relationship between $X$ and $Y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Combination of Random Variables\n",
    "\n",
    "$$ \\begin{align}\n",
    "E((a + bX) + (c + dY)) = a &+ bE(X) \\\\&+ c + dE(Y) \n",
    "\\\\\n",
    "Var((a + bX) + (c + dY)) = b^2Var(X) &+ d^2Var(Y) \n",
    "\\\\\n",
    "&+ 2bd\\times Cov(X, Y) \n",
    "\\end{align}$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise 6:\n",
    "\n",
    "A researcher suspected that the number of between-meal snacks eaten by students in a day during final examinations might depend on the number of tests a student had to take on that day. The accompanying table shows joint probabilities, estimated from a survey.  \n",
    "\n",
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(a) What are the mean and standard deviation of $X$?  \n",
    "\n",
    "(b) What are the mean and standard deviation of $Y$?  \n",
    "\n",
    "(c) What is the covariance between $X$ and $Y$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(d) What is the correlation between $X$ and $Y$?  \n",
    "\n",
    "(e) Are $X$ and $Y$ independent?  Justify your answer.  \n",
    "\n",
    "(f) What is the conditional probability distribution of $Y$ given $X = 2$?  \n",
    "\n",
    "(g) What is the expected value of $Y$ given $X = 2$?  \n",
    "\n",
    "(h) Suppose your tummy stress level $S$, on a scale of 0 to 45 (no pain to extreme pain), is given by $S = 5X + 10Y$. Find the mean and variance of $S$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(a) What are the mean and standard deviation of $X$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(b) What are the mean and standard deviation of $Y$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(c) What is the covariance between $X$ and $Y$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(d) What is the correlation between $X$ and $Y$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(e) Are $X$ and $Y$ independent?  Justify your answer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(f) What is the conditional probability distribution of $Y$ given $X = 2$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(g) What is the expected value of $Y$ given $X = 2$?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "|     |     |     |  X  |     |\n",
    "|:---:|:---:|:---:|:---:|:---:|\n",
    "|     |     | 0   | 1   |  2  |\n",
    "|     | 0 | 0.10 | 0.09 | 0.08 |\n",
    "|  Y  | 1 | 0.11 | 0.12 | 0.14 |\n",
    "|     | 2 | 0.06 | 0.13 | 0.17 |\n",
    "\n",
    "\n",
    "(h) Suppose your tummy stress level $S$, (no pain to extreme pain), is given by $S = 5X + 10Y$. Find the mean and variance of $S$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Point Estimation  \n",
    "\n",
    "**Example**  \n",
    "\n",
    "Victor owns a coffee shop, and he wants to model the number of customers arrive at the coffee shop during morning rush hours, in order to schedule his staff more efficiently and provide better customer service. He recorded the number of customer arrived per hour for a few mornings, and here is the data he collected: 74, 94, 93, 79, 74, 80, 73, 88, 63, 97.  \n",
    "\n",
    "1) How should Victor model the data? What model should he use?  \n",
    "\n",
    "2) What do we need to estimate in order to model the data?  \n",
    "\n",
    "3) How can we estimated it/them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Maximum Likelihood Estimation (MLE)  \n",
    "\n",
    "We want to find the value of the parameter that maximizes the likelihood function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The likelihood function  \n",
    "\n",
    "Probability mass function (discrete) / probability density function (continuous): $P(X = x | \\text{ fixed known parameters})$  \n",
    "\n",
    "\n",
    "The likelihood function: looks almost the same as above, **EXCEPT**:\n",
    "* $x$ is fixed and known now  \n",
    "\n",
    "* parameter values are unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### The log-likelihood function  \n",
    "\n",
    "To maximize the likelihood function, we usually take the log of it and maximize the log-likelihood function instead for the following reasons:  \n",
    "\n",
    "* Maximizing the log-likelihood function is equivalent to maximizing the likelihood function  \n",
    "\n",
    "\n",
    "* It is often easier to take the derivative of a log-likelihood function and solving for the parameter being maximized  \n",
    "    * i.e. it is easier to work with sums than products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* It makes computation easier\n",
    "    * one issue with calculating small probabilities with a computer is numerical underflow - once the values get sufficiently small, they will be rounded to 0 and we will lose all information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Maximization  \n",
    "\n",
    "To maximize the log-likelihood, we introduced two methods:  \n",
    "\n",
    "* Analytical method: take the derivative of the function with respect to the parameter(s), set it/them to 0 and solve for the parameter value(s)  \n",
    "\n",
    "\n",
    "* Numerical method: for a range of values that the parameter(s) can take, calculate the corresponding log-likelihood, the value(s) that give the maximum log-likelihood value will be the MLE  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Method of Moments (MOM)\n",
    "\n",
    "We make method of moments estimates by equating the population moments to the sample moments, and solve for the parameters we are trying to estimate.  \n",
    "\n",
    "First, distinction between population moments and sample moments:  \n",
    "\n",
    "* Populations moments are like attributes of the population or distribution, $E(X), E(X^2), E(X^3), \\dots$\n",
    "    * population moments are functions of population parameters\n",
    "\n",
    "\n",
    "* Sample moments are the estimates of these attributes based on the sample, $\\frac{1}{n} \\sum_{i = 1}^n X_i, \\frac{1}{n} \\sum_{i = 1}^n X_i^2, \\frac{1}{n} \\sum_{i = 1}^n X_i^2,  \\dots$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Similar to the idea of population parameters vs sample statistics, population moments are unknown but fixed numbers, while sample moments can be calculated from the sample but it varies from sample to sample.  \n",
    "\n",
    "\n",
    "* Population moments do not equal sample moments as a fact, but in order to estimate the population parameters experssed in the population moments, we set them to be equal and solve for the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mean Squared Error (MSE)  \n",
    "\n",
    "One way to evaluate the estimators is to use the mean squared error (MSE).  \n",
    "\n",
    "$$MSE = E[(\\hat{\\theta} - \\theta)^2] = Var(\\hat{\\theta}) + (Bias(\\hat{\\theta}))^2 $$  \n",
    "\n",
    "where $Bias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$\n",
    "\n",
    "**Example**   \n",
    "\n",
    "Victor doesn't like our way of estimating $\\lambda$, and he came up with his own estimator for $\\lambda$,  \n",
    "\n",
    "$$ \\hat{\\theta} = \\frac{1}{4} X_1 + \\frac{1}{2} X_2 + \\frac{1}{4} X_3 $$  \n",
    "\n",
    "What is the MSE of his estimator?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Central Limit Theorem\n",
    "\n",
    "* The CLT states that if random samples of size $n$ are repeatedly drawn from any population with mean $\\mu$ and variance $\\sigma^2$, then when $n$ is large, the distribution of the sample means will be approximately Normal:  \n",
    "\n",
    "\n",
    "$$ \\bar{X} \\dot{\\sim} N(\\mu, \\frac{\\sigma^2}{n}) $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**How Large is Large Enough?**  \n",
    "\n",
    "* For **most** distributions, $n > 30$ will give a sampling distribution that is nearly Normal   \n",
    "\n",
    "\n",
    "* For **fairly symmetric** distributions, $n > 15$  \n",
    "\n",
    "\n",
    "* For **Normal** population distributions, the sampling distribution of the mean is always Normally distributed\n",
    "\n",
    "**Example**  \n",
    "\n",
    "The service times for customers coming to the coffee shop have a mean of 1 minute and a variance of 1 at each counter. What is the probability that 80 customers can be serviced in less than 1 hours by one counter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Confidence Intervals\n",
    "\n",
    "### For one population mean\n",
    "\n",
    "* With known population standard deviation $\\sigma$: **z-based** \n",
    "\n",
    "$$ \\bar{X} \\pm 1.96 \\frac{\\sigma}{\\sqrt{n}} $$  \n",
    "\n",
    "* Population standard deviation unknown: **t-based** \n",
    "\n",
    "$$ \\bar{X} \\pm t \\left( \\frac{s}{\\sqrt{n}} \\right) $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Example**  \n",
    "\n",
    "New York is known as \"the city that never sleeps\". A random sample of 25 New Yorkers were asked how much sleep they get per night. Statistical summaries of these data are shown below. Construct a 95% confidence interval for the average amount of sleep New Yorkers get per night.  \n",
    "\n",
    "<img src=\"images/ny_sleep.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### For one population proportion  \n",
    "\n",
    "The 95% confidence interval is give by:  \n",
    "\n",
    "$$ \\hat{p} \\pm 1.96 \\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}} $$  \n",
    "\n",
    "We always construct **z-based** confidence intervals for proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Difference in means  \n",
    "\n",
    "* For large sample sizes, the 95% confidence interval for the difference in two populations means is given by:  \n",
    "\n",
    "$$ \\bar{X} - \\bar{Y} \\pm 1.96 \\sqrt{\\frac{s_X^2}{n_1} + \\frac{s_Y^2}{n_2}} $$  \n",
    "\n",
    "* For small sample sizes:  \n",
    "\n",
    "$$ \\bar{X} - \\bar{Y} \\pm t \\sqrt{\\frac{s_X^2}{n_1} + \\frac{s_Y^2}{n_2}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Difference in proportions  \n",
    "\n",
    "The 95% confidence interval for the difference in two population proportions:  \n",
    "\n",
    "$$ (\\hat{p}_1 - \\hat{p}_2) \\pm 1.96 \\sqrt{\\frac{\\hat{p}_1(1 - \\hat{p}_1)}{n_1} + \\frac{\\hat{p}_2(1 - \\hat{p}_2)}{n_2}} $$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
