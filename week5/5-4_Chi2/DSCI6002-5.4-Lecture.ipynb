{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 5.4: Chi-Square Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Goodness-of-fit test\n",
    "* $\\chi^2$ distribution\n",
    "* Test for independence\n",
    "* Multiple tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "* Learn about $\\chi^2$ distribution and chi-square tests\n",
    "* Become familiar with goodness of fit and independence tests\n",
    "* Understand Bonferroni correcction for multiple comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Story Time\n",
    "\n",
    "Long long ago, there lived a candy fairy. His name is Lee Skittle.  \n",
    "\n",
    "Lee's hobby was to turn flowers into candies with different colors, and he told his dog, Aria, that he always had the same number of candies of each color.  \n",
    "\n",
    "Aria got hungry one day, and decided to eat one bag of Lee's candies that he had hidden under a giant mushroom. Aria loved math, so as she was eating the candies, she counted how many candies of each color she ate.  \n",
    "\n",
    "Lee was furious when he discovered that his candies were gone, and he decided to marry Aria to Mr. M., a brown bear who liked wearing colorful clothes. The night before Aria and Mr. M.'s wedding, Aria told Lee, I want to tell you a secret about your candies, \"you had been wrong all these years, Lee, you didn't have the same number of candies of each color - there were 11 red candies, 11 green candies, 10 yellow candies, 10 purple candies and 8 orange candies in the bag I found.\"  \n",
    "\n",
    "Lee was shocked about what Aria told him that night, and he thought a lot about the distribution of the candy colors. It was very very important to him that all the colors were evenly distributed, but he had made more than a googol candies, most of which had already been eaten, so he couldn't count all of the candies by colors.  \n",
    "\n",
    "What should Lee do?..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assum that the bag of candies that Aria ate was a simple random sample of all the candies Lee had made.\n",
    "\n",
    "| |Red|Green|Yellow|Purple|Orange|\n",
    "|:-|-:|-:|-:|-:|-:|-:|\n",
    "|Counts|11|11|10|10|8|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How can we check if the entire candy population is evenly distributed across the different colors?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Chi-square goodness-of-fit test\n",
    "\n",
    "The Chi-square test allows us to evaluate goodness of fit for a model. \n",
    "\n",
    "So, we can suggest a model and then compare our sample against that model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$H_0: P(Red)=P(Green)=P(Yellow)=P(Purple)=P(Orange)=0.2$  \n",
    "$H_a:$ At least one proprotion is not equal to the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| |Red|Green|Yellow|Purple|Orange|\n",
    "|:-|-:|-:|-:|-:|-:|-:|\n",
    "|Counts|11|11|10|10|8|\n",
    "|Expected|10|10|10|10|10|\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from IPython.display import Latex, YouTubeVideo\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from statsmodels.distributions.empirical_distribution import ECDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "colors = [\"Red\", \"Green\", \"Yellow\", \"Blue\", \"Orange\"]\n",
    "counts = [11, 11, 10, 10, 8]\n",
    "e = 10\n",
    "\n",
    "print(pd.DataFrame({\"Counts\": counts, \"Expected\": [e] * len(counts)}, index=colors).T)\n",
    "\n",
    "stats.chisquare(counts, [e] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we don't have evidence to say that the candies aren't distributed evenly across different colors.  \n",
    "\n",
    "Lee can finally have a good night sleep now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How does this work?  \n",
    "\n",
    "To conduct the test, first we need a test statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chi^2 = \\sum {\\left(O_i - E_i \\right)^2 \\over E_i}$$\n",
    "O is the observed count  \n",
    "E is the expected count\n",
    "\n",
    "So in our case:\n",
    "$$\\chi^2 = \\frac{(11-10)^2}{10} + \\frac{(11-10)^2}{10} + \\frac{(10-10)^2}{10} + \\frac{(10-10)^2}{10} + \\frac{(8-10)^2}{10}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "((11-10)**2 + (11-10)**2 + (10-10)**2 + (10-10)**2 + (8-10)**2) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum((o - e)**2 for o in counts) / e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The test statistic follows $\\chi^2$ distribution.\n",
    "\n",
    "Now we need to check this against the $\\chi^2$ distribution to get our p-value.  \n",
    "\n",
    "\n",
    "What is the $\\chi^2$ distribution again?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chi^2(k,x) = {1 \\over {2^\\frac{k}{2}\\Gamma\\left(\\frac{k}{2}\\right)}}x^{\\frac{k}{2}-1}e^{-\\frac{x}{2}}$$\n",
    "\n",
    "here $k$ is a parameter called the degrees of freedom  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For goodness of fit test, the degrees of freedom is number of categories minus one.  \n",
    "So for our skittles example the degrees of freedom is $5 - 1 = 4$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$\\Gamma(\\frac{k}{2})$ is the gamma function:  \n",
    "$$\\Gamma(n) = (n-1)!, n \\in \\mathbb{N}$$\n",
    "$$\\Gamma(t) = \\int\\limits_0^\\infty x^{t-1}e^{-x}dx$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "x = linspace(0.001, 9, 2000)\n",
    "\n",
    "degrees = [1, 2, 3, 4, 6, 8]\n",
    "\n",
    "for i in degrees:\n",
    "    dist = stats.chi2(df=i)\n",
    "    y = dist.pdf(x)\n",
    "    plot(x, y, label = '{} degrees of freedom'.format(i))\n",
    "    \n",
    "ylim(0, 0.6); legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats.chisquare(counts, [e] * 5)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = len(counts) - 1\n",
    "x = sum((o - e)**2 for o in counts) / e\n",
    "stats.chi2(df=df).sf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assumptions\n",
    "* That the data is randomly selected\n",
    "* The sample data consists of frequency counts for each of the different categories\n",
    "* For each category, the expected frequency need to be at least 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Story Continues..  \n",
    "\n",
    "After Aria and Mr. M. got married, in order to woo Aria's love, Mr. M. started making candies for her. He made two kinds of candies, one with chocolate and one with peanuts, and he liked to covered all the candies with colorful sugar coats.  \n",
    "\n",
    "Aria, loving math as aways, started counting the two different types of candies by colors. One day, she told Mr. M., \"M., my love, your chocolate candies and peanut candies don't have the same color distribution - the color distribution depends on the type of candy I'm eating.\"  Mr. M. tried to count all the candies he had in his pockets, but he didn't have enough fingers and toes.  \n",
    "\n",
    "How can Mr. M. check if Aria is right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Test for independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here are the counts of the candies Mr. M. had in his pocket, by color and candy type.\n",
    "\n",
    "| |Red|Green|Yellow|Blue|Orange|\n",
    "|:-|-:|-:|-:|-:|-:|-:|\n",
    "|Chocolate|7|2|11|8|5|\n",
    "|Peanuts|8|9|4|1|3|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"Chocolate\": [7, 2, 11, 8, 5], \"Peanut\": [8, 9, 4, 1, 3]}, index=colors).T\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$H_0$: the colors and candy types are independent  \n",
    "$H_a$: the colors and canday types are dependent  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.chi2_contingency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = stats.chi2_contingency(data)\n",
    "\n",
    "Latex(r\"$\\chi^2 = {:.4}; p = {:.2}$\".format(chi2, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chi^2 = \\sum {\\left(O_i - E_i \\right)^2 \\over E_i} = 12.87$$  \n",
    "\n",
    "$$ \\text{p-value}\\approx 0.01 $$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "p-value is small, so we reject the null hypothesis.  \n",
    "\n",
    "We have very strong evidence to conclude that Aria is right, the candy type and color distribution are dependent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How does this work?\n",
    "\n",
    "* It's actually the same thing as before, just without a model.\n",
    "* We calculate the expected values based on the data.\n",
    "* We can do this because we are able to obtain the joint probabilities from the contingency table\n",
    "* If the events are independent, $P(A \\cap B) = P(A) \\times P(B)$  \n",
    "* So, assuming independence gives us the probabilities for calculating the expected counts\n",
    "* $H_0:$ the two variables are independent\n",
    "* $H_a:$ the two variables are not independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "| |Red|Green|Yellow|Blue|Orange|\n",
    "|:-|-:|-:|-:|-:|-:|-:|\n",
    "|Chocolate|7|2|11|8|5|\n",
    "|Peanuts|8|9|4|1|3|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is $P(color = red)$  \n",
    "What is $P(type = chocolate)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$P(color = red) = \\frac{15}{58}$$\n",
    "$$P(type = chocolate) = \\frac{33}{58}$$\n",
    "If we assume independence this means:  \n",
    "$$P(color = red\\ \\cap\\ type = chocolate) = \\frac{15}{58} \\times \\frac{33}{58} $$  \n",
    "Since there are 58 elements in the table, the expected value for red chocolate candy is $\\frac{15}{58} \\times \\frac{33}{58} \\times 58$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Can you fill in the table with expected counts?  \n",
    "\n",
    "| |Red|Green|Yellow|Blue|Orange|\n",
    "|:-|-:|-:|-:|-:|-:|-:|\n",
    "|Chocolate||||||\n",
    "|Peanuts|||||||\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "expected_df = pd.DataFrame(expected, index=['Chocolate', 'Peanut'], columns=colors)\n",
    "\n",
    "print(\"E(red chocolate candy) = {:.4}\".format(15 / 58 * 33))\n",
    "\n",
    "print(\"\\nObserved:\\n{}\".format(data))\n",
    "print(\"\\nExpected:\\n{}\".format(expected_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Degrees of freedom for independence test is (number of rows - 1) * (number of columns - 1). So in our example we have (5 - 1) * (2 - 1) = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sum up $\\chi^2$\n",
    "\n",
    "* Distribution for sum of squares of standard normals\n",
    "* Can be used for goodness of fit tests and tests of independence\n",
    "* These are really the same thing mathematically, but they use slightly different methods so get called different things\n",
    "* Both tests extract a p-value using $\\sum{(O_i - E_i)^2\\over E_i}$  \n",
    "* For goodness of fit, the expected values are what you get out of your model, and a low p-value means you reject the model\n",
    "* For independence tests you calculate the $E_i$ using an assumption of independence of the variables, then a low p-value means they are not independent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "_and now for something completely different!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('IhJQp-q1Y1s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install ipy-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipy_table import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Data snooping\n",
    "\n",
    "## Neural correlates of interspecies perspective taking in the post-mortem Atlantic Salmon: \n",
    "\n",
    "### An argument for multiple comparisons correction\n",
    "\n",
    "![salmon](http://www.wired.com/images_blogs/wiredscience/2009/09/fmri-salmon.jpg)  \n",
    "\n",
    "http://prefrontal.org/files/posters/Bennett-Salmon-2009.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about the need for having our hypotheses determined *before* looking at the summary table. Here is a simple example to illustrate the danger of looking at summaries of the data before deciding which hypothesis to test.\n",
    "\n",
    "Below, I will create complete noise datasets but try to find \"the best model\". There is nothing wrong with finding the best model, what is wrong is trusting the results of the summary table **after having chosen this as the best model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = randn(50000).reshape((50,1000))\n",
    "Y = randn(50)\n",
    "Z = (X.T.dot(Y - Y.mean())) / Y.std()\n",
    "qqplot(Z)\n",
    "sm.OLS(Y, sm.add_constant(X[:,0])).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collection of 1000 $T$ statistics looks pretty close to a normal (with 50 degrees of freedom). This is not surprising.\n",
    "\n",
    "Now, let's look at the largest $T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "largest_T = abs(Z).argmax()\n",
    "sm.OLS(Y, sm.add_constant(X[:, largest_T])).fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $T$ statistic is much larger in absolute value than it should be.\n",
    "Let's repeat this experiment many times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def largest_T_sim(printit = False):\n",
    "    X = randn(500).reshape((50,10))\n",
    "    Y = randn(50)\n",
    "    Z = (X.T.dot(Y - Y.mean())) / Y.std()\n",
    "    largest_T = abs(Z).argmax()\n",
    "    lm = sm.OLS(Y, sm.add_constant(X[:,largest_T])).fit()\n",
    "    if printit:\n",
    "        print(lm.summary())\n",
    "    return lm.pvalues[1]\n",
    "\n",
    "largest_T_sim(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this many times and store the $p$-values. What will their distribution look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pval = pd.Series(largest_T_sim() for _ in range(200))\n",
    "ecdf = ECDF(pval)\n",
    "plot(ecdf.x, ecdf.y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type I error\n",
    "\n",
    "How likely are we to conclude there is an effect if we use these $p$-values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ecdf(.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pval.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Hypothesis Testing\n",
    "==================================\n",
    "<!-- adapted from http://www.stat.berkeley.edu/~mgoldman/Section0402.pdf -->\n",
    "\n",
    "Why is multiple testing a problem?\n",
    "--------------------------------\n",
    "Say you have a set of hypotheses that you wish to test simultaneously.  The first idea that might come to mind is to test each hypothesis separately, using some level of significance. At first blush, this doesn't seem like a bad idea.  However, consider a case where you have 20 hypotheses to test, and a significance level of 0.05.  What's the probability of observing at least one significant result just due to chance?\n",
    "$$\\begin{align}\n",
    "P(\\text{at least one significant result}) &= 1 - P(\\text{no significant results})\\\\\n",
    "&=1 - (1 - 0.05)^{20} \\\\\n",
    "&\\approx 0.64\n",
    "\\end{align}$$\n",
    "So, with 20 tests being considered, we have a 64% chance of observing at least one significant result, even if all of the tests are actually not significant.  In many fields,  it's  not  unusual  for  the  number  of  simultaneous  tests  to  be  quite  a bit larger than 20...  and the probability of getting a significant result simply due to chance keeps going up. \n",
    "\n",
    "Methods for dealing with multiple testing frequently call for adjusting in some way, so that the probability of observing at least one significant result due to chance remains below your desired significance level.\n",
    "\n",
    "Bonferroni Correction\n",
    "--------------------------------\n",
    "The Bonferroni correction sets the significance cut-off at $\\alpha/n$. For example, in the example above, with 20 tests and $\\alpha=0.05$, you'd only reject a null hypothesis if the p-value is less than 0.0025.  The Bonferroni correction tends to be a bit too conservative.  To demonstrate this, let's calculate the probability of observing at least one signi\f",
    "cant result when using the correction just described:\n",
    "$$\\begin{align}\n",
    "P(\\text{at least one significant result}) &= 1 - P(\\text{no significant results})\\\\\n",
    "&=1 - (1 - 0.0025)^{20} \\\\\n",
    "&\\approx 0.0488\n",
    "\\end{align}$$\n",
    "Here, we're just a shade under our desired 0.05 level.  We benefit here from assuming that all tests are independent of each other.  In practical applications, that is often not the case.  Depending on the correlation structure of the tests, the Bonferroni correction could be extremely conservative, leading to a high rate of false negatives.\n",
    "\n",
    "False Discovery Rate\n",
    "--------------------------------\n",
    "In large-scale multiple testing, you may be better served by controlling the false discovery rate (FDR). This is defined as the proportion of false positives among all significant results.  The FDR works by estimating some rejection region so that, on average, FDR $\\lt\\alpha$.\n",
    "\n",
    "Comparing the three\n",
    "--------------------------------\n",
    "First, let's make some data.  For kicks and grins, we'll use the random normals in such a way\n",
    "that we'll know what the result of each hypothesis test should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Multiple Comparisons\n",
    "\n",
    "The scenario of testing many pairs of groups is called **multiple comparisons**.  \n",
    "\n",
    "* Suppose we want test a new way of teaching writing to students, and we randomly assign students to the new way of teaching and the standard way of teaching writing. Students in the two groups can be compared in terms of grammar, spelling, organization, content, and so on. As more attributes are compared, it becomes more likely that the two groups will appear to differ on at least one attribute by random chance alone.    \n",
    "\n",
    "\n",
    "* Suppose we consider the efficacy of a drug in terms of the reduction of any one of a number of disease symptoms. As more symptoms are considered, it becomes more likely that the drug will appear to be an improvement over existing drugs in terms of at least one symptom.\n",
    "\n",
    "**What can we do?**\n",
    "\n",
    "For hypothesis testing, the problem of multiple comparisons (also known as the multiple testing problem) results from the increase in type I error that occurs when statistical tests are used repeatedly.\n",
    "\n",
    "The **Bonferroni correction** suggests that a more stringent significance level is more appropriate for these tests:  \n",
    "\n",
    "$$ \\alpha^* = \\alpha / K $$  \n",
    "\n",
    "Where $\\alpha$ is usually set to be 0.05, and $K$ is the total number of comparisons.  \n",
    "\n",
    "The **Bonferroni correction** is one of the most conservative methods for counteracting the problem of multiple comparisons.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed(27)\n",
    "x = randn(1000)\n",
    "x[-100:] += 3\n",
    "p = 1 - stats.norm.cdf(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions should all be familiar. Here, we've made a vector, x, of length 1000.  The first 900 entries are random numbers with a standard normal distribution.  The last 100 are random numbers from a normal distribution with mean 3 and sd 1.  Note that I didn't need to indicated the sd of 1 in the second bit; it's the default value. The next line of code is finding the p-values for a hypothesis test on each value of x.  The hypothesis being tested is that the value of x is not difierent from 0, given the entries are drawn from a standard normal distribution.  The alternate is a one-sided test, claiming that the value is larger than 0.\n",
    "\n",
    "Now,  in  this  case,  we  know  the  truth:  The  first  900  observations  should  fail  to  reject the null hypothesis:  they are, in fact, drawn from a standard normal distribution and any difference between the observed value and 0 is just due to chance.  The last 100 observations should reject the null hypothesis:  the difference between these values and 0 is not due to chance alone.\n",
    "\n",
    "Let's take a look at our p-values, adjust them in various ways, and see what sort of results\n",
    "we get.  Note that, since we all will have our own random vectors, your figures will probably\n",
    "be a different from mine.  They should be pretty close, however."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = p <= 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def result_table(test_stats, pos=r'\\text{Positive}', neg=r'\\text{Negative}', head=' ', neg_count=900):\n",
    "    pos_count = len(test_stats) - neg_count\n",
    "    tbl = [(head, neg, pos, r'\\text{Total}'),\n",
    "           ('\\mu=0', neg_count - sum(test_stats[ :neg_count]), sum(test_stats[ :neg_count]), neg_count),\n",
    "           ('\\mu=3', pos_count - sum(test_stats[-pos_count:]), sum(test_stats[-pos_count:]), pos_count)]\n",
    "    return list(map(lambda r: list(map('${}$'.format, r)), tbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbl = result_table(test, 'p\\le0.05', 'p\\gt0.05')\n",
    "make_table(tbl)\n",
    "set_global_style(align=\"right\", width=67)\n",
    "apply_theme('basic_both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The type I error rate (false positives) is 48/900 = 0.0533.  The type II error rate (false\n",
    "negatives) is 6/100 = 0.06.  Note that the type I error rate is awfully close to our $\\alpha$, 0.05. This isn't a coincidence: $\\alpha$ can be thought of as some target type I error rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Bonferroni correction\n",
    "\n",
    "We have $\\alpha=0.05$, and $1000$ tests, so the Bonferroni correction will have us looking for p-values smaller than $0.00005$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bonftest = p <= 0.05/1000\n",
    "tbl = result_table(bonftest, r'p\\le\\frac{.05}{1000}', r'p\\gt\\frac{.05}{1000}')\n",
    "make_table(tbl)\n",
    "set_global_style(align=\"right\", width=67)\n",
    "apply_theme('basic_both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the type I error rate is 0/900, but the type II error rate has skyrocketed to 0.78.  We've reduced our false positives at the expense of false negatives.  Ask yourself: which is worse?  False positives or false negatives?  Note:  there isn't a firm answer. It really depends on the context of the problem and the consequences of each type of error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. FDR\n",
    "For the FDR, we want to consider the ordered p-values.  We'll see if the kth ordered p-value\n",
    "is larger than $\\frac{k\\times.05}{1000}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "psort = sorted(p)\n",
    "fdrtest = [p_val <= (psort.index(p_val) + 1) * .05/1000 for p_val in p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's parse this bit of code. I want the string of Trues and Falses to be in the same order as the original p-values, so we can easily pick off the errors. I start by creating a separate variable, `psort`, which holds the same values as `p`, but sorted from smallest to largest. Say I want to test only the first entry of p:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p[0] <= psort.index(p[0]) * .05/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p[0]` picks off the first entry from the vector `p`.  `psort.index(p[0])` looks through the vector `psort`, finds the first value that's exactly equal to `p[0]`, and returns the index of the vector it is. In my random vector, `psort.index(p[0])` returns 185.  That means that, if you put all the p-values in order from smallest to largest, the 185th largest value is the one that appears first in my vector.  The value you get might differ pretty wildly if you change the `random.seed` above in this case. Anyhow, on to see how the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tbl = result_table(fdrtest, r'p\\le\\frac{k\\times.05}{1000}', r'p\\gt\\frac{k\\times.05}{1000}')\n",
    "make_table(tbl)\n",
    "set_global_style(align=\"right\", width=73)\n",
    "apply_theme('basic_both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a type I error rate of 6/900 = 0.0067.  The type II error rate is now 34/100\n",
    "= 0.30, a big improvement over the Bonferroni correction!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can simplify this process by using the `multipletests` function in `statsmodels.stats.multitest`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bonftest2 = multipletests(p, alpha=.05, method='bonferroni')[0]\n",
    "tbl = result_table(bonftest2, head='Bonferroni')\n",
    "make_table(tbl)\n",
    "set_global_style(align=\"right\")\n",
    "apply_theme('basic_both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fdrtest2 = multipletests(p, alpha=.05, method='fdr_bh')[0]\n",
    "tbl = result_table(fdrtest2, head='FDR')\n",
    "make_table(tbl)\n",
    "set_global_style(align=\"right\", width=50)\n",
    "apply_theme('basic_both')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
