{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 6.3: Multiple Regressions II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "\n",
    "* Dummy variables for indicator and categorical data\n",
    "* Interaction terms\n",
    "    * Interactions between continuous and categorical variables\n",
    "    * Interactions between continuous and continuous variables\n",
    "* Variable selection - stepwise regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from seaborn import lmplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fake_puppy_data = pd.DataFrame()\n",
    "fake_puppy_data['num_puppies'] = np.abs(np.random.normal(3,4,size=1000)).round()\n",
    "fake_puppy_data[fake_puppy_data['num_puppies']==0] = 1\n",
    "other_animals = ['yes','no']\n",
    "fake_puppy_data['has_other_animals'] = np.random.choice(other_animals,replace=True,size=1000,p=[0.2,0.8])\n",
    "age_groups = ['puppy','dog','elderly dog']\n",
    "fake_puppy_data['age_group'] = np.random.choice(age_groups,replace=True,size=1000,p=[0.5,0.2,0.3])\n",
    "fake_puppy_data['score'] = 4.231  * fake_puppy_data['num_puppies'] + \\\n",
    "                           24.213 * (fake_puppy_data['has_other_animals']=='yes') + \\\n",
    "                           -0.340 * (fake_puppy_data['has_other_animals']=='no') + \\\n",
    "                           20.453 * (fake_puppy_data['age_group']=='puppy') + \\\n",
    "                           -6.543 * (fake_puppy_data['age_group']=='dog') + \\\n",
    "                           14.568 * (fake_puppy_data['age_group']=='elderly dog') + \\\n",
    "                           6.574  * (fake_puppy_data['num_puppies'] * 1.*(fake_puppy_data['has_other_animals'] == 'yes')) + \\\n",
    "                           3.486  * (fake_puppy_data['num_puppies'] * 1.*(fake_puppy_data['age_group'] == 'puppy')) + \\\n",
    "                           0.182  * (fake_puppy_data['num_puppies'] * 1.*(fake_puppy_data['age_group'] == 'elderly dog')) + \\\n",
    "                           12.381 + \\\n",
    "                           np.random.normal(15,3,size=1000)\n",
    "fake_puppy_data['score'] = 100 * ((fake_puppy_data['score']-fake_puppy_data['score'].min())/(fake_puppy_data['score'].max() - fake_puppy_data['score'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## More stories\n",
    "\n",
    "My wife likes pictures of puppies. To document this I had her look at and score 1000 photos of puppies (I did not actually do this one in real life)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "fake_puppy_data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data dictionary\n",
    "\n",
    "* num_puppies is number of puppies in the photo\n",
    "* has_other_animals is yes if there are other animals in photo, no otherwise\n",
    "* age_group describes the average age of the dogs in the photo, either puppy, dog, or elderly dog\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Question:\n",
    "Can I run my current data through statsmodels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X = fake_puppy_data[['num_puppies','has_other_animals','age_group']]\n",
    "y = fake_puppy_data.score\n",
    "model = sm.OLS(y, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Any ideas on how to deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Add dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = fake_puppy_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['others_yes'] = 1 * (data.has_other_animals == 'yes') \n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How the dummy variable works  \n",
    "  \n",
    "\n",
    "$x_i = \\left\\{\\begin{array}{11} 1 & \\mbox{if ith picture has other animals} \\\\ 0 & \\mbox{if ith picture has no other animals} \\end{array} \\right. $\n",
    "\n",
    "$$y_i \\sim \\beta_0 + \\beta_1 x_i + \\epsilon_i = \\left\\{\\begin{array}{11} \\beta_0 + \\beta_1 + \\epsilon_i & \\mbox{if ith picture has other animals} \\\\ \\beta_0 + \\epsilon_i & \\mbox{if ith picture has no other animals} \\end{array} \\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Important \n",
    "\n",
    "When you do this you are changing the interpretation of your intercept.  \n",
    "* What did the intercept mean before?\n",
    "* What does it mean now?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Categorical variables\n",
    "\n",
    "* Basically the same as dummy variables, but with more than two levels\n",
    "* In general you need number of categories - 1 columns to encode a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data['puppy'] = 1 * (data.age_group == 'puppy')\n",
    "data['elderly'] = 1 * (data.age_group == 'elderly dog')\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How this works  \n",
    "  \n",
    "\n",
    "$x_{i1} = \\left\\{\\begin{array}{11} 1 & \\mbox{if the ith picture has mostly puppies} \\\\ 0 & \\mbox{if the ith picture does not have mostly puppies} \\end{array} \\right. $\n",
    "\n",
    "$x_{i2} = \\left\\{\\begin{array}{11} 1 & \\mbox{if the ith picture has mostly elderly dogs} \\\\ 0 & \\mbox{if the ith picture does not have mostly elderly dogs} \\end{array} \\right. $\n",
    "\n",
    "$$y_i \\sim \\beta_0 + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\epsilon_i = \\left\\{\\begin{array}{111} \\beta_0 + \\beta_1 + \\epsilon_i & \\mbox{if ith picture has mostly puppies} \\\\ \\beta_0 + \\beta_2 + \\epsilon_i & \\mbox{if ith picture has mostly elderly dogs} \\\\ \\beta_0 + \\epsilon_i & \\mbox{if ith picture has mostly middle aged dogs}\\end{array} \\right.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Once again\n",
    "Interpretation of coefficients changes\n",
    "\n",
    "* What is $\\beta_0$ now?\n",
    "* What is $\\beta_1$?\n",
    "* What is $\\beta_2$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do we use this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y = data.score\n",
    "X = data[['num_puppies','others_yes','puppy','elderly']]\n",
    "X = sm.add_constant(X)  # <- add in constant term\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "results = model.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note before we move on\n",
    "\n",
    "You can add dummy variables to a data frame automatically with pd.get_dummies\n",
    "\n",
    "### Important\n",
    "This adds columns for all categories, so it does not have a baseline, you can remove the columns you don't want afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.get_dummies(fake_puppy_data)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Our model before was fairly good, but how to investigate?\n",
    "\n",
    "Since we only have 1 continuous variable we can visualize in two dimensions, and we would expect different offsets for each line, but the same slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.plot(x='num_puppies', y='score', kind='scatter');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lets try to clear this up a little"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_data = data[data.puppy == 1]\n",
    "p_data.plot(x='num_puppies', y='score', kind='scatter', color='b', label='puppy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Our model assumes that the slopes of these lines are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scatter(p_data.num_puppies,\n",
    "        results.fittedvalues[data.puppy == 1],\n",
    "        color='m',\n",
    "        marker='x',\n",
    "        label='fitted puppies')\n",
    "legend(loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_data.plot(x='num_puppies', y='score', kind='scatter', color='b', label='puppy', alpha=.2)\n",
    "scatter(p_data.num_puppies,\n",
    "        results.fittedvalues[data.puppy == 1],\n",
    "        color='m',\n",
    "        marker='x',\n",
    "        label='fitted puppies')\n",
    "legend(loc=4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lmplot('num_puppies', 'score', p_data, 'has_other_animals', fit_reg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactions\n",
    "\n",
    "We can add interaction terms by multiplying columns together\n",
    "$$y \\sim \\beta_0 + \\beta_1 \\times x_1 + \\beta_2 \\times x_2 + \\beta_3 \\times x_1 \\times x_2 $$\n",
    "so if $x_2$ is other animals:\n",
    "$$y_i = \\left\\{\\begin{array}{11} (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) \\times x_{1i} + \\epsilon_i & \\mbox{if the ith photo has other animals} \\\\ \\beta_0 + \\beta_1 \\times x_{1i} + \\epsilon_i & \\mbox{if ith picture has no other animals} \\end{array} \\right.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lmplot('num_puppies', 'score', fake_puppy_data, 'has_other_animals', 'age_group');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our lives easier, we are going to start using R-style formulas courtesy of the library [`patsy`](http://patsy.readthedocs.io/en/latest/) which should have been installed automatically along with statsmodels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model2 = smf.ols(formula='score ~ num_puppies + has_other_animals + age_group', data=fake_puppy_data)\n",
    "results2 = model2.fit()\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that when we use a formula, `patsy` automatically adds an Intercept term and transforms categorical variables into dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use formulas to model interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "formula = 'score ~ num_puppies * others_yes + puppy + elderly'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "model3 = smf.ols(formula = formula,data = data)\n",
    "results3 = model3.fit()\n",
    "results3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "p_data.plot(x='num_puppies',y='score',kind='scatter',color='b',label='puppy')\n",
    "scatter(p_data.num_puppies, results3.fittedvalues[data['puppy']==1], color='y', marker='x' ,label = 'fitted puppies');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Interactions between multiple continuous variables\n",
    "\n",
    "We can add interaction terms by multiplying columns together\n",
    "$$y \\sim \\beta_0 + \\beta_1 \\times x_1 + \\beta_2 \\times x_2 + \\beta_3 \\times x_1 \\times x_2 $$\n",
    "so if $x_1$ and $x_2$ are both continuous:\n",
    "$$y_i = \\beta_0 + (\\beta_1 + \\beta_3 \\times x_{2i}) \\times x_{1i} + \\beta_2 \\times x_{2i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So, the value of the coefficient for $x_1$ now depends on the value of $x_2$.  \n",
    "For interpretation you still consider the other variables held constant, but when there are interactions you cannot say how much one will improve without specifying the value the other one is held constant at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Stepwise Regression\n",
    "\n",
    "Stepwise regression is a good simple tool for determining parameters to include in models. Care must be taken in its use, as it is easy to fall into the trap of trusting it more than you should. If you have a large number of parameters, or a small amount of data, it is probably best to use another tool. There are multiple ways to perform stepwise regression, the general procedures for stepwise regression are:\n",
    "\n",
    "* Forward Stepwise Regression:\n",
    "    * Start with some form of minimal model (like intercept only)\n",
    "    * Add other variables into your model based on which ones maximally increase adjusted $R^2$ (or some other test criteria)\n",
    "    * Continue until you run out of variables or adding any variable reduces the quality of your  model\n",
    "* Backward Stepwise Regression:\n",
    "    * Start with some form of maximal model (include all variables)\n",
    "    * Remove variables that least improve the model (or have insignificant p-values), one at a time\n",
    "    * Stop when you can no longer improve your model by removing variables\n",
    "* Bidirectional Stepwise Regression:\n",
    "    * Do both of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Useful things to know\n",
    "\n",
    "In order to implement stepwise regression you have to know how to compare models. There are several ways to do this:\n",
    "\n",
    "* Adjusted $R^2$, AIC, BIC, F-test. These are model quality metrics (will discuss more on next slide)\n",
    "* p-values for coefficients. These can be used to evaluate importance of individual predictors for the model.\n",
    "* Others I haven't mentioned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Model quality metrics\n",
    "* Adjusted $R^2$  \n",
    "$$Adjusted\\ R^2 = 1 - {\\frac{RSS}{(n-k-1)} \\over \\frac{TSS}{(n-1)}}$$\n",
    "    * Want adjusted $R^2$ close to one, includes penalties for number of predictors (k)  \n",
    "\n",
    "* AIC (Akaike Information Criterion)  \n",
    "$$AIC = -2log(L) + 2k$$\n",
    "    * L is likelihood for the model and k is number of predictors, want the model with the lowest AIC value  \n",
    "    \n",
    "* BIC (Bayesian Information Criterion)\n",
    "$$BIC = -2log(L) + 2log(n)$$\n",
    "    * Very similar to AIC, but since log(n) > 2 for n > 7 adds a larger penalty for additional predictors, once again want the lowest. n is the sample size.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Backward stepwise example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "boring_fake_data_1 = pd.DataFrame()\n",
    "boring_fake_data_1['A'] = np.random.normal(25,5,1000)\n",
    "boring_fake_data_1['C'] = np.random.normal(75,15,1000)\n",
    "boring_fake_data_1['B'] = 5 * boring_fake_data_1['A'] - 2 * boring_fake_data_1['C'] + np.random.normal(20,3,1000)\n",
    "boring_fake_data_1['D'] = np.random.uniform(-50,50,1000)\n",
    "boring_fake_data_1['response'] = 50 * boring_fake_data_1['A'] + \\\n",
    "                                 3 * boring_fake_data_1['B'] + \\\n",
    "                                 50 * boring_fake_data_1['C'] + \\\n",
    "                                 50 + np.random.normal(350,150,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "boring_fake_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fit the full model with all of the independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "formula = 'response ~ A + B + C + D'\n",
    "model1 = smf.ols(formula=formula, data=boring_fake_data_1)\n",
    "results1 = model1.fit()\n",
    "results1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Eliminate the least significant variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "formula = 'response ~ A + C + D'\n",
    "model2 = smf.ols(formula=formula,data=boring_fake_data_1)\n",
    "results2 = model2.fit()\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## And again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "formula = 'response ~ A + C'\n",
    "model3 = smf.ols(formula=formula,data=boring_fake_data_1)\n",
    "results3 = model3.fit()\n",
    "results3.summary()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
